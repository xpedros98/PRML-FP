{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Activites_recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "3zM8ZPlejpIv",
        "2Odu_pI8DVOR",
        "2omxMTpba1Nn",
        "RHSThYDrDmG4",
        "jN5xbrAngp_I",
        "k7uryzEljTUo",
        "8Fylv0atymOy",
        "omohbYXCj3wG",
        "5x1W9BiOS6fS",
        "aq7NEi0UTCR6",
        "jZZj_2EaTGLY",
        "ffvL9xeGTMm8",
        "rmpSVYa7TRng",
        "rc7GU6ORb96E",
        "hnaIZGUYdGcW",
        "h1Cx_qYj5rxi",
        "iLtgVEjYDrMz",
        "DU__WFRV7Xyp",
        "FmUYiZSv6VJP",
        "1942ybP674l0",
        "xVuwFox08Ck2",
        "VzeEt2Ie8Gjb"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0LrK50EqOHp"
      },
      "source": [
        "FINAL PROJECT: **Activities Recognition**.\n",
        "\n",
        "**Pattern Recognition & Machine Learning.**\n",
        "\n",
        "**UPC - MUAR**\n",
        "\n",
        "Authors: **Javier Pedrosa Alias & Óscar Palacín Domínguez.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zM8ZPlejpIv"
      },
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjHkuf43f9xs"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIMlbWHGqbAY"
      },
      "source": [
        "Import all the necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAh2FZrb2Lym"
      },
      "source": [
        "from google.colab import drive\n",
        "import io\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import time\n",
        "import statistics as st\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Principal Component Analysis.\n",
        "from sklearn import decomposition      \n",
        "from sklearn.preprocessing import StandardScaler  \n",
        "\n",
        "# Feature selection methods.\n",
        "from sklearn.feature_selection import SelectKBest, chi2, f_classif, mutual_info_classif\n",
        "\n",
        "# Clustering.\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "from sklearn import mixture\n",
        "\n",
        "# Probabilistic classifiers.\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "\n",
        "# Random forests.\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Gradient boosting.\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Performance evaluation.\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Odu_pI8DVOR"
      },
      "source": [
        "# Data handling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wpa_bUznMK1"
      },
      "source": [
        "Upload the CSV dataset; convert it to a pandas dataframe; and replace the NaNs by the means of the same class values, in the case there are some ones:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORHrnIE9jxxo"
      },
      "source": [
        "t0 = time.time()\n",
        "\n",
        "complete_ds = pd.read_csv('/content/drive/MyDrive/PRML/PRML - FP/dataset.csv',sep=\",\", header=0)\n",
        "ds_shape = complete_ds.shape\n",
        "\n",
        "# Eliminate the test samples.\n",
        "mask = complete_ds.label != \"test\"  # Get a boolean vector for each data row.\n",
        "ds = complete_ds.loc[mask]\n",
        "\n",
        "# Discard sample with NaNs.\n",
        "ds_nonnan = ds.dropna()\n",
        "\n",
        "# Save the target.\n",
        "target = ds[\"label\"]\n",
        "labels = list(set(target))\n",
        "\n",
        "# Remove last headers (because they are not data, are checksums to debug).\n",
        "undesired_headers = [\"fields_num\", \"props_num\", \"#ref\", \"Time_max\", \"Time_min\", \"Time_mean\", \"Time_q1\", \"Time_q2\", \"Time_q3\", \"LatitudeDegrees_max\", \"LatitudeDegrees_min\", \"LatitudeDegrees_mean\", \"LatitudeDegrees_q1\", \"LatitudeDegrees_q2\", \"LatitudeDegrees_q3\", \"LongitudeDegrees_max\", \"LongitudeDegrees_min\", \"LongitudeDegrees_mean\", \"LongitudeDegrees_q1\", \"LongitudeDegrees_q2\", \"LongitudeDegrees_q3\"]\n",
        "for header in undesired_headers:\n",
        "    del ds[header]\n",
        "\n",
        "\n",
        "# Check the NaN gaps.\n",
        "for label in labels:\n",
        "    mask = ds.label == label\n",
        "    curr_ds = ds.loc[mask]\n",
        "    print(label)\n",
        "\n",
        "    for header in ds.keys():\n",
        "        curr_list = list(curr_ds[header])\n",
        "        if header != \"label\":\n",
        "            curr_nonnans = []\n",
        "            index_list = []  # Save a reference to know which values are not a number.\n",
        "            for i in range(len(curr_list)):\n",
        "                if not np.isnan(curr_list[i]):\n",
        "                    curr_nonnans.append(curr_list[i])\n",
        "                else:\n",
        "                    index_list.append(curr_ds.index[i])\n",
        "\n",
        "            if len(curr_nonnans) != 0 and len(index_list) != 0:\n",
        "                curr_mean = st.mean(curr_nonnans)\n",
        "                for i in index_list:\n",
        "                    ds[header][i] = curr_mean\n",
        "                # mask = bool_list\n",
        "                # column = header\n",
        "                # complete_ds.loc[mask, column] = curr_mean  # Substitute the true values of mask in the specified column.\n",
        "            elif len(curr_nonnans) == 0:\n",
        "                print(\"All 0 for: \" + label + \" -> \" + header)\n",
        "                for i in index_list:\n",
        "                    ds[header][i] = 0\n",
        "\n",
        "ds.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2omxMTpba1Nn"
      },
      "source": [
        "# Dimensionallity reduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGwJjia2a3_f"
      },
      "source": [
        "Different dimensionallity approaches are going to be performed. The one that shows a better behavior will be the selected.\n",
        "1. First is necessary to split attributes and class labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s58GBB8erAyQ"
      },
      "source": [
        "X = ds[['AltitudeMeters_max','AltitudeMeters_min','AltitudeMeters_mean','AltitudeMeters_q1','AltitudeMeters_q2', 'AltitudeMeters_q3',\\\n",
        "        'HeartRatebpm_max','HeartRatebpm_min','HeartRatebpm_mean','HeartRatebpm_q1','HeartRatebpm_q2', 'HeartRatebpm_q3',\\\n",
        "        'Speed_max','Speed_min','Speed_mean','Speed_q1','Speed_q2', 'Speed_q3','RunCadence_max','RunCadence_min','RunCadence_mean',\\\n",
        "        'RunCadence_q1','RunCadence_q2','RunCadence_q3','gps_speed_min','gps_speed_mean','gps_speed_q2','gps_speed_q3','gps_acc_min',\\\n",
        "        'gps_acc_mean','gps_acc_q2','gps_acc_q3']]\n",
        "y = ds['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHSThYDrDmG4"
      },
      "source": [
        "## PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-s81YwpyaYW6"
      },
      "source": [
        "Scaling data (normalize) before performing PCA."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ybewux4GCAoM"
      },
      "source": [
        "XS = StandardScaler().fit_transform(X)\n",
        "XS.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfKU_VwvCj9i"
      },
      "source": [
        "PCA to scaled data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "th8qfjIKCmsY"
      },
      "source": [
        "pca = decomposition.PCA(n_components=32).fit(XS)\n",
        "print('eigenvalues = {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} '.format(*pca.explained_variance_))\n",
        "print('Explained variance = {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} {} '.format(*pca.explained_variance_ratio_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhzEM_93DHFE"
      },
      "source": [
        "Principal components and explained variance\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4v_GPZetDFf0"
      },
      "source": [
        "100*pca.explained_variance_ratio_.cumsum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HYt1mj1DSR5"
      },
      "source": [
        "The cumulative summatory of the explained variance ratio should be greater than a 95%, since the eight principal components with largest eigenvalues capture 95.95% of the variance in the data.\n",
        "Project the data in a space of reduced dimensionality:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P45-vu1TDy7O"
      },
      "source": [
        "XS_pca = pca.transform(XS)\n",
        "XS_pca.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cyNEyeJfsFw"
      },
      "source": [
        "dfpca = pd.DataFrame(XS_pca[:,0:8],columns=['PCA1', 'PCA2','PCA3', 'PCA4','PCA5', 'PCA6','PCA7','PCA8'])\n",
        "\n",
        "fig = plt.figure(figsize=(8,8))\n",
        "\n",
        "dfpca['label'] = y.array\n",
        "\n",
        "ax_pca = sns.pairplot(data=dfpca, hue= 'label')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hSFOTxjbVWr"
      },
      "source": [
        "## Feature selection methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv6rUnwzfHmr"
      },
      "source": [
        "To know which features are the most relevant in the dataset, different feature selection methods are going to be applied."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jN5xbrAngp_I"
      },
      "source": [
        "### Correlation heatmap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUjn78khgoeA"
      },
      "source": [
        "# Get correlations of each features in dataset.\n",
        "corrmat = X.corr()\n",
        "top_corr_features = corrmat.index\n",
        "plt.figure(figsize=(30,30))\n",
        "\n",
        "# Plot heat map.\n",
        "g=sns.heatmap(X[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOa0ihmjsmJl"
      },
      "source": [
        "# With the following function we can select highly correlated features\n",
        "# it will remove the first feature that is correlated with anything other feature.\n",
        "\n",
        "def correlation(dataset, threshold):\n",
        "    col_corr = set()  # Set of all the names of correlated columns\n",
        "    corr_matrix = dataset.corr()\n",
        "    for i in range(len(corr_matrix.columns)):\n",
        "        for j in range(i):\n",
        "            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n",
        "                colname = corr_matrix.columns[i]  # getting the name of column\n",
        "                col_corr.add(colname)\n",
        "    return col_corr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhjtoVLAsrBe"
      },
      "source": [
        "corr_features = correlation(X,0.7);\n",
        "len(set(corr_features))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSZ8SSZXyUGg"
      },
      "source": [
        "corr_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "le78eb_4yXlz"
      },
      "source": [
        "# Drop the highly correlated features.\n",
        "X_corr = X.drop (corr_features,axis=1)\n",
        "X_corr.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFjMjRUKyj-d"
      },
      "source": [
        "print(\"Original dataset dimension is = {} and the obtained with drop out highly correlated values is = {}.\".format(X.columns.size,X_corr.columns.size))\n",
        "print(\"The less correlated labels are: {}\".format(X_corr.columns))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoA_6lJx1zYj"
      },
      "source": [
        "Normalize the data before using it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQT9g0KJ1uVO"
      },
      "source": [
        "XS_corr = StandardScaler().fit_transform(X_corr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22MGY2-30_4h"
      },
      "source": [
        "Plot the dataset obtained."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vSg2AOp0-j-"
      },
      "source": [
        "dfcorr = pd.DataFrame(XS_corr,columns=['AltitudeMeters_max', 'HeartRatebpm_max', 'Speed_max', 'Speed_min',\n",
        "       'RunCadence_min', 'gps_speed_min', 'gps_acc_min', 'gps_acc_mean',\n",
        "       'gps_acc_q2', 'gps_acc_q3'])\n",
        "\n",
        "fig = plt.figure(figsize=(8,8))\n",
        "\n",
        "dfcorr['label'] = y.array\n",
        "\n",
        "ax_corr = sns.pairplot(data=dfcorr, hue = 'label')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7uryzEljTUo"
      },
      "source": [
        "### K best feature selector (NOT APPLIED!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0Uoze3BUVB0"
      },
      "source": [
        "F_classif ANOVA F-value between label/feature for classification tasks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dDFu8TrQlGD"
      },
      "source": [
        "X_f_class = SelectKBest(f_classif, k=20).fit_transform(X, y) \n",
        "X_f_class.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JERz9r0zXqwB"
      },
      "source": [
        "Mutual_info_classif Mutual information for a discrete target."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tatyowLJWGPx"
      },
      "source": [
        "X_f_mutual_info_classif = SelectKBest(mutual_info_classif, k=20).fit_transform(X, y) \n",
        "X_f_mutual_info_classif.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdLxWMgIQnsI"
      },
      "source": [
        "It does not work because X have negative values!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiDIDDb14aMZ"
      },
      "source": [
        "# X_chi = SelectKBest(chi2, k=1).fit_transform(X, y) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Fylv0atymOy"
      },
      "source": [
        "# Supervised techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xS1rroZXIQBg"
      },
      "source": [
        "Uncomment the line that you want to use and comment the other one:\n",
        "1. PCA Dimensionallity reduction dataset.\n",
        "2. Correlation Dimensionallity reduction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAS-Mz_C5LwK"
      },
      "source": [
        "# Xtrain, Xtest, ytrain, ytest = train_test_split(XS_pca, y, random_state=0,train_size=0.7)     # PCA\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(XS_corr, y, random_state=0,train_size=0.7)  # Correlation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omohbYXCj3wG"
      },
      "source": [
        "## Probabilistic classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9DAnF3KI2x-"
      },
      "source": [
        "Five different Probabilistic Classifiers are been considered:\n",
        "1. Linear Discriminant Analysis (LDA).\n",
        "2. Quadratic Discriminant Analysis (QDA).\n",
        "3. Naive Bayes (NB).\n",
        "4. K-Neares Neighbours (KNN).\n",
        "5. Decision Trees (DT)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5x1W9BiOS6fS"
      },
      "source": [
        "### LDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RatN7Zy3TWTr"
      },
      "source": [
        "clf_lda = LinearDiscriminantAnalysis(n_components=7,priors=None)\n",
        "clf_lda_trained = clf_lda.fit(Xtrain, ytrain)\n",
        "\n",
        "# Make predictions.\n",
        "ypred_lda = clf_lda.predict(Xtest)\n",
        "\n",
        "# Performance evaluation.\n",
        "as_lda = accuracy_score(ytest, ypred_lda)\n",
        "cm_lda = confusion_matrix(ytest, ypred_lda) # The confusion matrix is configured as: columns -> Real | Rows -> Predicted\n",
        "cr_lda = classification_report(ytest,ypred_lda)\n",
        "\n",
        "\n",
        "# Performance evaluation.\n",
        "print('Accuracy score: ')\n",
        "print(as_lda)\n",
        "print('Confusion matrix: ')\n",
        "print(cm_lda)\n",
        "print('Classification report: ')\n",
        "print(cr_lda)\n",
        "\n",
        "# Plot the Confusion Matrix.\n",
        "sns.heatmap(cm_lda/np.sum(cm_lda), annot=True, linewidths=0.5, linecolor=\"green\", fmt=\".2%\")\n",
        "plt.xlabel(\"y_pred\")\n",
        "plt.ylabel(\"y_true\")\n",
        "plt.title('LDA')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aq7NEi0UTCR6"
      },
      "source": [
        "### QDA\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpNX6tjjUtDK"
      },
      "source": [
        "clf_qda = QuadraticDiscriminantAnalysis(priors=None,store_covariance=True)\n",
        "clf_qda_trained = clf_qda.fit(Xtrain, ytrain)\n",
        "\n",
        "# Make predictions.\n",
        "ypred_qda = clf_qda.predict(Xtest)\n",
        "\n",
        "# Performance evaluation.\n",
        "as_qda = accuracy_score(ytest, ypred_qda)\n",
        "cm_qda = confusion_matrix(ytest, ypred_qda) # The confusion matrix is configured as: columns -> Real | Rows -> Predicted\n",
        "cr_qda = classification_report(ytest,ypred_qda)\n",
        "\n",
        "\n",
        "# Performance evaluation.\n",
        "print('Accuracy score: ')\n",
        "print(as_qda)\n",
        "print('Confusion matrix: ')\n",
        "print(cm_qda)\n",
        "print('Classification report: ')\n",
        "print(cr_qda)\n",
        "\n",
        "# Plot the Confusion Matrix.\n",
        "sns.heatmap(cm_qda/np.sum(cm_qda), annot=True, linewidths=0.5, linecolor=\"green\", fmt=\".2%\")\n",
        "plt.xlabel(\"y_pred\")\n",
        "plt.ylabel(\"y_true\")\n",
        "plt.title('QDA')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZZj_2EaTGLY"
      },
      "source": [
        "### NB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl9BKXFwWtku"
      },
      "source": [
        "clf_gnb = GaussianNB()\n",
        "ytrained_gnb = clf_gnb.fit(Xtrain, ytrain)\n",
        "\n",
        "# Make predictions.\n",
        "ypred_gnb = clf_gnb.predict(Xtest)\n",
        "\n",
        "# Performance evaluation.\n",
        "as_gnb = accuracy_score(ytest, ypred_gnb)\n",
        "cm_gnb  = confusion_matrix(ytest, ypred_gnb) # The confusion matrix is configured as: columns -> Real | Rows -> Predicted\n",
        "cr_gnb  = classification_report(ytest,ypred_gnb)\n",
        "\n",
        "\n",
        "# Performance evaluation.\n",
        "print('Accuracy score: ')\n",
        "print(as_gnb)\n",
        "print('Confusion matrix: ')\n",
        "print(cm_gnb)\n",
        "print('Classification report: ')\n",
        "print(cr_gnb)\n",
        "\n",
        "# Plot the Confusion Matrix.\n",
        "sns.heatmap(cm_gnb/np.sum(cm_gnb), annot=True, linewidths=0.5, linecolor=\"green\", fmt=\".2%\")\n",
        "plt.xlabel(\"y_pred\")\n",
        "plt.ylabel(\"y_true\")\n",
        "plt.title('Naive Bayes')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffvL9xeGTMm8"
      },
      "source": [
        "### KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nq3-6hZQXdbO"
      },
      "source": [
        "clf_knn = KNeighborsClassifier(n_neighbors=3)\n",
        "ytrained_knn = clf_knn.fit(Xtrain, ytrain) \n",
        "\n",
        "# Make predictions.\n",
        "ypred_knn = clf_knn.predict(Xtest)\n",
        "\n",
        "# Performance evaluation.\n",
        "as_knn = accuracy_score(ytest, ypred_knn)\n",
        "cm_knn  = confusion_matrix(ytest, ypred_knn) # The confusion matrix is configured as: columns -> Real | Rows -> Predicted\n",
        "cr_knn  = classification_report(ytest,ypred_knn)\n",
        "\n",
        "\n",
        "# Performance evaluation.\n",
        "print('Accuracy score: ')\n",
        "print(as_knn)\n",
        "print('Confusion matrix: ')\n",
        "print(cm_knn)\n",
        "print('Classification report: ')\n",
        "print(cr_knn)\n",
        "\n",
        "# Plot the Confusion Matrix.\n",
        "sns.heatmap(cm_knn/np.sum(cm_knn), annot=True, linewidths=0.5, linecolor=\"green\", fmt=\".2%\")\n",
        "plt.xlabel(\"y_pred\")\n",
        "plt.ylabel(\"y_true\")\n",
        "plt.title('Decision Trees')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmpSVYa7TRng"
      },
      "source": [
        "### DT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wg9WIoBtXjZ1"
      },
      "source": [
        "clf_dt = tree.DecisionTreeClassifier()\n",
        "ytrained_dt = clf_dt.fit(Xtrain,ytrain)\n",
        "\n",
        "# Make predictions.\n",
        "ypred_dt = clf_dt.predict(Xtest)\n",
        "\n",
        "# Performance evaluation.\n",
        "as_dt = accuracy_score(ytest, ypred_dt)\n",
        "cm_dt  = confusion_matrix(ytest, ypred_dt) # The confusion matrix is configured as: columns -> Real | Rows -> Predicted\n",
        "cr_dt  = classification_report(ytest,ypred_dt)\n",
        "\n",
        "\n",
        "# Performance evaluation.\n",
        "print('Accuracy score: ')\n",
        "print(as_dt)\n",
        "print('Confusion matrix: ')\n",
        "print(cm_dt)\n",
        "print('Classification report: ')\n",
        "print(cr_dt)\n",
        "\n",
        "# Plot the Confusion Matrix.\n",
        "sns.heatmap(cm_dt/np.sum(cm_dt), annot=True, linewidths=0.5, linecolor=\"green\", fmt=\".2%\")\n",
        "plt.xlabel(\"y_pred\")\n",
        "plt.ylabel(\"y_true\")\n",
        "plt.title('Decision Trees')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4vpPrq0XrEf"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "ax = plot_tree(ytrained_dt) \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rc7GU6ORb96E"
      },
      "source": [
        "## Random Forests (RF)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7nDbYcwc7Ss"
      },
      "source": [
        "clf_rf = RandomForestClassifier(max_depth=None, random_state=0)\n",
        "ytrained_rf = clf_rf.fit(Xtrain, ytrain)\n",
        "\n",
        "# Make predictions.\n",
        "ypred_rf = clf_rf.predict(Xtest)\n",
        "\n",
        "# Performance evaluation.\n",
        "as_rf = accuracy_score(ytest, ypred_rf)\n",
        "cm_rf = confusion_matrix(ytest, ypred_rf) # The confusion matrix is configured as: columns -> Real | Rows -> Predicted\n",
        "cr_rf = classification_report(ytest,ypred_rf)\n",
        "\n",
        "\n",
        "# Performance evaluation.\n",
        "print('Accuracy score: ')\n",
        "print(as_rf)\n",
        "print('Confusion matrix: ')\n",
        "print(cm_rf)\n",
        "print('Classification report: ')\n",
        "print(cr_rf)\n",
        "\n",
        "# Plot the Confusion Matrix.\n",
        "sns.heatmap(cm_rf/np.sum(cm_rf), annot=True, linewidths=0.5, linecolor=\"green\", fmt=\".2%\")\n",
        "plt.xlabel(\"y_pred\")\n",
        "plt.ylabel(\"y_true\")\n",
        "plt.title('Random forests')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnaIZGUYdGcW"
      },
      "source": [
        "##Gradient Bosting (GB)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-BV8WUDdO1t"
      },
      "source": [
        "# Gradient Boosting Classifier parameters.\n",
        "nestimator = 100\n",
        "learningrate = 1\n",
        "\n",
        "# Training the model.\n",
        "clf_gb = GradientBoostingClassifier(n_estimators=nestimator, learning_rate=learningrate, max_depth=None, random_state=0)\n",
        "ytrained_gb = clf_gb.fit(Xtrain, ytrain)\n",
        "\n",
        "# Make predictions.\n",
        "ypred_gb = clf_gb.predict(Xtest)\n",
        "\n",
        "# Performance evaluation.\n",
        "as_gb = accuracy_score(ytest, ypred_gb)\n",
        "cm_gb = confusion_matrix(ytest, ypred_gb) # The confusion matrix is configured as: columns -> Real | Rows -> Predicted\n",
        "cr_gb = classification_report(ytest,ypred_gb)\n",
        "\n",
        "\n",
        "# Performance evaluation.\n",
        "print('Accuracy score: ')\n",
        "print(as_gb)\n",
        "print('Confusion matrix: ')\n",
        "print(cm_gb)\n",
        "print('Classification report: ')\n",
        "print(cr_gb)\n",
        "\n",
        "# Plot the Confusion Matrix.\n",
        "sns.heatmap(cm_gb/np.sum(cm_gb), annot=True, linewidths=0.5, linecolor=\"green\", fmt=\".2%\")\n",
        "plt.xlabel(\"y_pred\")\n",
        "plt.ylabel(\"y_true\")\n",
        "plt.title('Random forests')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFEKK85ZW-wM"
      },
      "source": [
        "# Performance evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxYnjphOJc0q"
      },
      "source": [
        "In these section two different performance evaluation are computed for all the classifier:\n",
        "1. Confusion matrix.\n",
        "2. Classification report."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXbwT-DR8XjK"
      },
      "source": [
        "## Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ix2wQ4PXBzT"
      },
      "source": [
        "print('Confusion matrix LDA: ')\n",
        "print(cm_lda)\n",
        "print('Confusion matrix QDA: ')\n",
        "print(cm_qda)\n",
        "print('Confusion matrix NB: ')\n",
        "print(cm_gnb)\n",
        "print('Confusion matrix KNN: ')\n",
        "print(cm_knn)\n",
        "print('Confusion matrix DT: ')\n",
        "print(cm_dt)\n",
        "print('Confusion matrix RF: ')\n",
        "print(cm_rf)\n",
        "print('Confusion matrix GB: ')\n",
        "print(cm_gb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mz-JqDFbo5rI"
      },
      "source": [
        "classifiers = [\"LDA\", \"QDA\", \"GNB\", \"KNN\", \"DT\", \"RF\", \"GB\"]\n",
        "confusion_matrices = [cm_lda, cm_qda, cm_gnb, cm_knn, cm_dt, cm_rf, cm_gb]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgM78QPpocrj"
      },
      "source": [
        "fig, axes = plt.subplots(nrows=1,ncols=7,figsize=(21,3))\n",
        "\n",
        "for cls, cfm, ax in zip(classifiers, confusion_matrices, axes.flatten()):\n",
        "  sns.heatmap(cfm, annot=True, linewidths=0.5, linecolor=\"green\", fmt=\".0f\", ax = ax, cmap= \"Blues\")\n",
        "  ax.set_xlabel(\"y_pred\")\n",
        "  ax.set_ylabel(\"y_true\")\n",
        "  # ax.title.set_text(type(cls).__name__)\n",
        "  ax.title.set_text(cls)\n",
        "\n",
        "plt.tight_layout()    \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IC4MdJG8fF3"
      },
      "source": [
        "## Classification report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhREG_ki8Uuw"
      },
      "source": [
        "print('Classificaiton report LDA: ')\n",
        "print(cr_lda)\n",
        "print('Classificaiton report QDA: ')\n",
        "print(cr_qda)\n",
        "print('Classificaiton report NB: ')\n",
        "print(cr_gnb)\n",
        "print('Classificaiton report KNN: ')\n",
        "print(cr_knn)\n",
        "print('Classificaiton report DT: ')\n",
        "print(cr_dt)\n",
        "print('Classificaiton report RF: ')\n",
        "print(cr_rf)\n",
        "print('Classificaiton report GB: ')\n",
        "print(cr_gb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fM-fZHKHXxRc"
      },
      "source": [
        "If we look the confusion matrix of the different probabilistic classifiers we can ensure that the better performance is the one of the LDA."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1Cx_qYj5rxi"
      },
      "source": [
        "# Experimentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfgKqlZy6EE0"
      },
      "source": [
        "In this last section, the best classifiers performance is compared applying both PCA and Correlation dimensionality reduction (run only the one chosen on the \"Dimensionality reduction\" section)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjihJAeUEN0I"
      },
      "source": [
        "## PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-2nwALSE10h"
      },
      "source": [
        "In the case of the PCA dimensionality reduction the fourth best classifiers are the following: KNN, DT, RF and GB."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRhVsuNfESKZ"
      },
      "source": [
        "### KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMOqWw_RFoSd"
      },
      "source": [
        "dfknn = pd.DataFrame(Xtest[:,0:8],columns=['PCA1', 'PCA2','PCA3', 'PCA4','PCA5', 'PCA6','PCA7','PCA8'])\n",
        "\n",
        "fig = plt.figure(figsize=(8,8))\n",
        "\n",
        "dfknn['label'] = ypred_knn\n",
        "\n",
        "ax_knn = sns.pairplot(data=dfknn, hue= 'label')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPOXnviKFbCv"
      },
      "source": [
        "### DT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtTaLcKZHQze"
      },
      "source": [
        "dfdt = pd.DataFrame(Xtest[:,0:8],columns=['PCA1', 'PCA2','PCA3', 'PCA4','PCA5', 'PCA6','PCA7','PCA8'])\n",
        "\n",
        "fig = plt.figure(figsize=(8,8))\n",
        "\n",
        "dfdt['label'] = ypred_dt\n",
        "\n",
        "ax_dt = sns.pairplot(data=dfdt, hue= 'label')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2ctv5CwFf6C"
      },
      "source": [
        "### RF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxtZwv1oHWGm"
      },
      "source": [
        "dfrf = pd.DataFrame(Xtest[:,0:8],columns=['PCA1', 'PCA2','PCA3', 'PCA4','PCA5', 'PCA6','PCA7','PCA8'])\n",
        "\n",
        "fig = plt.figure(figsize=(8,8))\n",
        "\n",
        "dfrf['label'] = ypred_rf\n",
        "\n",
        "ax_rf = sns.pairplot(data=dfrf, hue= 'label')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRbDqIszFhAg"
      },
      "source": [
        "### GB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZznOBiK4HcI9"
      },
      "source": [
        "dfgb = pd.DataFrame(Xtest[:,0:8],columns=['PCA1', 'PCA2','PCA3', 'PCA4','PCA5', 'PCA6','PCA7','PCA8'])\n",
        "\n",
        "fig = plt.figure(figsize=(8,8))\n",
        "\n",
        "dfgb['label'] = ypred_gb\n",
        "\n",
        "ax_gb = sns.pairplot(data=dfgb, hue= 'label')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLtgVEjYDrMz"
      },
      "source": [
        "## Correlation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaJoc3UwEprc"
      },
      "source": [
        "In the case of the Correlation dimensionality reduction the fourth best classifiers are the following: KNN, DT, RF and GB."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DU__WFRV7Xyp"
      },
      "source": [
        "### Original"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWswv3S87bxa"
      },
      "source": [
        "dftrue = pd.DataFrame(Xtest,columns=['AltitudeMeters_max', 'HeartRatebpm_max', 'Speed_max', 'Speed_min',\n",
        "       'RunCadence_min', 'gps_speed_min', 'gps_acc_min', 'gps_acc_mean',\n",
        "       'gps_acc_q2', 'gps_acc_q3'])\n",
        "\n",
        "fig = plt.figure(figsize=(8,8))\n",
        "\n",
        "dftrue['label'] = ytest\n",
        "\n",
        "sns.pairplot(data=dftrue, hue = 'label')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92_yqwuH4FqF"
      },
      "source": [
        "dftrue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmUYiZSv6VJP"
      },
      "source": [
        "### KNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kvgjbm7vAesk"
      },
      "source": [
        "First it is necessary to convert the numpy predicted array to a pandas dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfyI3OsU5zWy"
      },
      "source": [
        "dfknn = pd.DataFrame(Xtest,columns=['AltitudeMeters_max', 'HeartRatebpm_max', 'Speed_max', 'Speed_min',\n",
        "       'RunCadence_min', 'gps_speed_min', 'gps_acc_min', 'gps_acc_mean',\n",
        "       'gps_acc_q2', 'gps_acc_q3'])\n",
        "\n",
        "fig = plt.figure(figsize=(8,8))\n",
        "\n",
        "dfknn['label'] = ypred_knn\n",
        "\n",
        "ax_knn = sns.pairplot(data=dfknn, hue= 'label')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1942ybP674l0"
      },
      "source": [
        "### DT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42nbGu7g8MkE"
      },
      "source": [
        "dfdt= pd.DataFrame(Xtest,columns=['AltitudeMeters_max', 'HeartRatebpm_max', 'Speed_max', 'Speed_min',\n",
        "       'RunCadence_min', 'gps_speed_min', 'gps_acc_min', 'gps_acc_mean',\n",
        "       'gps_acc_q2', 'gps_acc_q3'])\n",
        "\n",
        "fig = plt.figure(figsize=(8,8))\n",
        "\n",
        "dfdt['label'] = ypred_dt\n",
        "\n",
        "ax_dt = sns.pairplot(data=dfdt, hue = 'label')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVuwFox08Ck2"
      },
      "source": [
        "### RF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1y7oVXhZ8eKD"
      },
      "source": [
        "dfrf= pd.DataFrame(Xtest,columns=['AltitudeMeters_max', 'HeartRatebpm_max', 'Speed_max', 'Speed_min',\n",
        "       'RunCadence_min', 'gps_speed_min', 'gps_acc_min', 'gps_acc_mean',\n",
        "       'gps_acc_q2', 'gps_acc_q3'])\n",
        "\n",
        "fig = plt.figure(figsize=(8,8))\n",
        "\n",
        "dfrf['label'] = ypred_rf\n",
        "\n",
        "ax_rf = sns.pairplot(data=dfrf, hue = 'label')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GbTYz3C83zk"
      },
      "source": [
        "ypred_rf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzeEt2Ie8Gjb"
      },
      "source": [
        "### GB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ymsq6sh8p8J"
      },
      "source": [
        "dfgb = pd.DataFrame(Xtest,columns=['AltitudeMeters_max', 'HeartRatebpm_max', 'Speed_max', 'Speed_min',\n",
        "       'RunCadence_min', 'gps_speed_min', 'gps_acc_min', 'gps_acc_mean',\n",
        "       'gps_acc_q2', 'gps_acc_q3'])\n",
        "\n",
        "fig = plt.figure(figsize=(8,8))\n",
        "\n",
        "dfgb['label'] = ypred_gb\n",
        "\n",
        "ax_gb = sns.pairplot(data=dfgb, hue = 'label')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}